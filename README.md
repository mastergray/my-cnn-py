# my-cnn-py

A class that implements a Convolutional Neural Network ([CNN](https://en.wikipedia.org/wiki/Convolutional_neural_network)) using [Keras](https://keras.io/api/) in Python. 

## What Is a CNN?

Paraphased from ChatGPT:

> A Convolutional Neural Network (CNN or ConvNet) is a type of artificial neural network designed specifically for tasks involving images and spatial data. CNNs have proven to be highly effective in various computer vision tasks, such as image classification, object detection, image segmentation, and more. They work by systematically processing and learning hierarchical features from input data, typically images, through a series of layers. These layers include convolutional layers, pooling layers, and fully connected layers. 

> Convolution layers are the core building blocks of a CNN. Each convolutional layer applies a set of learnable filters (kernels) to the input image. Each filter detects specific patterns or features in the input data, such as edges, textures, or more complex structures. The filters slide (or convolve) across the input data, computing a dot product between the filter and a local region of the input. This operation extracts local features and produces feature maps. Multiple filters are used in each layer to capture different features. 

> After each convolution operation, an activation function (typically ReLU, Rectified Linear Unit) is applied element-wise to introduce non-linearity. This helps the network learn complex, non-linear relationships in the data. Pooling layers reduce the spatial dimensions of the feature maps. The most common pooling operation is max-pooling, where the maximum value within a local region is retained, and the rest are discarded. This operation helps reduce the computational complexity of the network and makes it more invariant to small translations and distortions in the input data. After several convolutional and pooling layers, the network typically has one or more fully connected layers. These layers perform high-level feature extraction and classification. Each neuron in these layers is connected to every neuron in the previous layer. These layers are often used in the final stages of the network to produce output predictions, such as class probabilities.

> The final fully connected layer usually has as many neurons as there are classes in the classification task. The output of this layer represents the network's prediction for each class, often normalized using a softmax activation function to obtain class probabilities. Once trained, the CNN can make predictions on new, unseen data by forwarding it through the network. The class with the highest probability in the output layer is typically chosen as the final prediction.

> CNNs excel at capturing hierarchical features in data, making them particularly effective for tasks like image classification, object detection, and image segmentation, where local and global patterns are essential for accurate predictions. Their ability to automatically learn these features from raw data sets them apart from traditional computer vision methods.


The CNN we are going to try to implement here is one that can "learn" to classify digits 0-9 from the [MINST](https://github.com/mastergray/my-minst-py) dataset. It's essetinally the CNN example model from Francois Chollet's [Deep Learning With Python](https://www.amazon.com/Learning-Python-Second-Fran%C3%A7ois-Chollet/dp/1617296864/ref=sr_1_1?crid=Q16L9QS1VXT4&keywords=deep+learning+with+python&qid=1695571267&sprefix=deep+learning+with+python%2Caps%2C105&sr=8-1) but encapulated as a class to help me better understand/remeber what stuff is/does. 

## Notes

- When we use a [Conv2D](https://keras.io/api/layers/convolution_layers/convolution2d/) layer in a Keras model - we are applying a convolution operation using a sliding window of a specific size that are learning features from a specific number of filters. During training, the network adjusts the weights and biases associated with each filter in a way that allows them to recognize and extract relevant features from the input data. Further, the filter itself is essentially a linear transformation that is applied to a sliding window (also known as a receptive field or kernel) over the input data. Each filter is represented by a set of learnable weights and a bias term. These weights serve as the parameters of the linear transformation. During the convolution operation, the filter's weights are multiplied element-wise with the values in the receptive field, and the result is summed up. This operation is essentially a dot product between the filter and the local region of the input data. The filter is applied to the input data by sliding it across the spatial dimensions of the input. At each position, the filter computes the dot product with the values within its receptive field. The sliding window moves step by step, covering different portions of the input data. hrough backpropagation and optimization algorithms like stochastic gradient descent (SGD), the network learns to update the filter's parameters to minimize the prediction error (loss) on the training data. This adjustment is how filters learn to recognize relevant features from the input data.

- Where we use a [MaxPooling2D](https://keras.io/api/layers/pooling_layers/max_pooling2d/) is a Keras model - we are downsampling some given region of the input data defined by a pool size (e.g. pool_size=2 means a region of 2x2), where "downsampling" means we are finding the maximum value in that pool that represents the most prominemt feature in that region. Doing this not only allows us to reduce the dimenionality of the input data - which in turn redudecs the computational cost of the model -  but also allows us to emphasize more important features while supressing less important information. Further, as we increase the number of filters for each Conv2D laters, we are enabling the model to learn a broader randge of features - so if we increase the number of filters as the input data travels through more layers we can help reinforce this "spatial hiearchy" between featurs of the image. That is to say, we start by looking at very specific features with a small number of filters, and more general features as we increase the number of filters. By applying max pooling after each convulotion layer then, we can help preserve prominient features that are both specific and general. 

- Translation invariance refers to the property of a system or a model to recognize and respond consistently to an object or pattern regardless of its position or location within the input data. Translation invariance  helps a CNN generalize because objects and features can appear at different positions in an image due to various factors, such as changes in perspective, rotation, or the natural variability in how objects are arranged. By being translation-invariant, a system or model is better equipped to handle these variations and make accurate predictions or classifications. Further, a key benefit of max pooling is that it introduces a degree of translation invariance. Since only the maximum value within each local region is retained, the pooling operation highlights the presence of key features regardless of their precise position within the pooling window. In other words, the network becomes less sensitive to small shifts or translations in the input data. Max pooling then helps the network generalize better to variations in the position and orientation of features or objects within the input data. It focuses on the most salient information, making the network more robust to the inherent variability in real-world data.

- [Sparse Categorial Cross Entropy](https://keras.io/api/losses/probabilistic_losses/#sparsecategoricalcrossentropy-class) is a loss function that should be used when there are two or more label classes - though it maybe best suited if images can only belong to one of those classes. For multi-label classification, [Binary Cross Entropy](https://keras.io/api/losses/probabilistic_losses/#binarycrossentropy-class) should be considered instead - this is because by using binary cross entroy loss along with sigmoid activation in an output layer, the model can learn to predict the probability of each class independently and can handle the multi-label nature of a classification problem effectively.


### References

- [Introduction to deep learning for computer vision](https://github.com/fchollet/deep-learning-with-python-notebooks/blob/master/chapter08_intro-to-dl-for-computer-vision.ipynb)

